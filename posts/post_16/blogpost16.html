<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Zaria Dancer">
<meta name="dcterms.date" content="2024-05-12">
<meta name="description" content="A post from a Jupyter notebook">

<title>Explorations with LLMs - Integration of Large Language Models in Customer Service Interactions</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Explorations with LLMs</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Integration of Large Language Models in Customer Service Interactions</h1>
                  <div>
        <div class="description">
          A post from a Jupyter notebook
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">LLMs</div>
                <div class="quarto-category">prompting</div>
                <div class="quarto-category">research</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Zaria Dancer </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 12, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="exploring-the-integration-of-large-language-models-in-customer-service-interactions-implications-and-considerations" class="level1">
<h1>Exploring the Integration of Large Language Models in Customer Service Interactions: Implications and Considerations</h1>
<p><strong>Zaria Dancer</strong></p>
<hr>
<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>This paper aims to explore the integration of Artificial Intelligence, specifically Large Language Models (LLMs), into customer service contexts and interactions. AI’s ever-advancing technology presents potential benefits and challenges, and exploring scholarly sources and applied evidence provides a comprehensive base knowledge of how LLMs are utilized in customer service contexts. This paper explores the implications of all parties - businesses, consumers, and service workers - with as focus on key considerations like explainability, the need for human oversight, privacy and data concerns, and scalability.</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Large Language Models (LLMs) are a classification of artificial intelligence (AI) with capabilities including generating and processing human-like text. These models can understand and respond to complex questions and statements - making their potential powerfully forceful within the customer service landscape. Conventionally, customer service interactions depend to human service representatives to handle requests, resolve problems, and build crucial rapport with customers. This approach provides personalization through attention, empathy, and specificity, but there are limitations such as limited availability, long wait times, and possible inconsistencies in quality. The scope of this paper aims to examine the possibility of leveraging LLMs to address these limitations and enhance the overall customer service experiences. Companies like Microsoft and Kroger are adopting AI to service customers, which leads to questions regarding AI influence and if traditional service aspects will remain relevant going forward <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. AI is disrupting certain industries, and the services industry is directly impacted. All parties are utilizing AI throughout the service experience - customers and firms. Furthermore, analyzing existing research and empirical findings will ensure a clear understanding of operative LLM integration into customer service challenges, while still recognizing the potential challenges and ethical considerations <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
</section>
<section id="the-role-of-llms-in-customer-service" class="level2">
<h2 class="anchored" data-anchor-id="the-role-of-llms-in-customer-service">The Role of LLMs in Customer Service</h2>
<p>Before the upsurge of LLMs, the customer service industry depending on human interactions between representatives and customers through emails, phone calls, and in-person interactions. Online shopping experiences empower shoppers who may experience impediments without the help of sales people; these settings allow for automation and development of interactive tools to create a seamless consumer experience. Regardless of the direct presence of personal assistants, this technology provides an opportunity to leverage the best attributes to cultivate a connected shipping experience for customers - including personalization and customization<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<p>The traditional methods foster human connections, but also comes with its limitations such as limited availability outside of business hours or long wait times. LLMs provide an approach that optimizes and automates features of the customer service process. Possible benefits include: Quick Responses, Cost-Efficiency, and Scalability. Artificial intelligence has the capabilities to ensure high-quality, consistent, and automated performance which impacts as satisfaction drivers and increases consumer expectations<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. LLMs have the potential create a seamless customer experience across various channels. Customers could initiate a conversation with an LLM chatbot on a company’s website and then continue the same conversation smoothly on the company’s social media platform or mobile app <a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. LLMs can provide responses with rapid speed, which significantly decreases wait times. Moreover, LLMs can process high volumes of information and inquiries at once, ensuring quality and consistent service despite the consumer demand<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. Furthermore, LLMs can automate tasks ad reduce the need for human interactions Overall, this can lead to cost savings for business, which is why several companies have adopted these emerging technologies<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p>
</section>
<section id="implications-of-llm-integration" class="level2">
<h2 class="anchored" data-anchor-id="implications-of-llm-integration">Implications of LLM Integration</h2>
<p>Although LLMs offer numerous potential benefits, there are several key aspects that require meticulous attention. LLMs resent privacy concerns surrounding data security and confidentiality. Customers data is sensitive and should be protected with vigorous safeguards. Ensuring privacy, confidentiality, and preventing data breaches is a serious priority. Moreover, LLMs are built using training data meaning their accuracy is directly correlated to the quality of responses. Due to the possibility of error, continuous improvement and monitoring is vital <a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. Furthermore, transparency and equity are significant. Artificial Intelligence present possible errors, discrepancies, and bias in algorithms, so businesses must prioritize responsible use of technology and innovation<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>.</p>
</section>
<section id="human-oversight" class="level2">
<h2 class="anchored" data-anchor-id="human-oversight">Human Oversight</h2>
<p>At this current point in AI’s technological advancement stage, human oversight is still essential within LLM-assisted customer service interactions. Humans can handle complex inquires and conversations that may require genuine consideration, empathy, and a nuanced understanding. Human expertise is vital within these situations and LLM usage within customer service situations <a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>. LLMs may be programmed to emulate empathy and other human qualities, but they lack the emotional intelligence and the capabilities to build rapport and relationships provided by human customer service agents. The harmony of collaborative approaches between humans and AI for premium customer service. Moreover, AI is seen as a way to augment human capabilities - not completely replace customer service representatives <a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>.</p>
<p>The findings of a scenario-based experiment with 567 participants presents findings that display that human customer service representatives surpass AI chatbots when the relevant product attribute(s) are experiential. On the contrary, AI chatbots are preferred when the customer is inquiring about functional attributes<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>. Moreover, the three aspects assessed for influencing customer satisfaction in this context were perceived waiting time and information quality. These insights offer businesses valuable information regarding possible options for service agent types to assist their customers during their online-shopping journey<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>.</p>
</section>
<section id="case-study" class="level2">
<h2 class="anchored" data-anchor-id="case-study">Case Study</h2>
<p>Examining LLM Integration in Airline Customer Service</p>
<p>Scenario: A traveler needs to change their flight reservation due to a last-minute schedule conflict.</p>
<p>Traditional Interaction: The traveler might call the airline’s customer service number and wait (on hold) for 1O minutes before being paired with a representative. After they are connected, they would explain their situation and request a change for the flight reservation. Then, the representative would access the flight information system, process the modifications, and confirm the new flight details with the customer. This process can be time-consuming and intensive, especially during peak travel times - this also increases wait times for customers. The entire process takes approximately 15 minutes on the lower end.</p>
<p>LLM-assisted Interaction: The traveler accesses the airline’s website or mobile app to initiate a chat with an LLM chatbot. The LLM utilizes Natural Language Processing (NLP) to understand the traveler’s inquiry about a flight change. The LLM accesses a knowledge base containing flight information and policies. Then the LLM could:</p>
<p>Identify the traveler’s existing reservation details.</p>
<p>Present the traveler with available flight options for the desired change.</p>
<p>Guide the traveler through the selection process and confirm the changes.</p>
<p>Provide the traveler with a confirmation email containing the updated flight information.</p>
<p>The entire process takes approximately 5 minutes.</p>
<p>Limitations of LLMs: Acknowledging the limitations of LLMs is significant, and LLMs pose challenges in regards to handling complex customer service scenarios. Some situations require empathy or nuanced understanding, such as dealing with an upset frustrated customer whose flight was cancelled.</p>
</section>
<section id="considerations-and-recommendations" class="level2">
<h2 class="anchored" data-anchor-id="considerations-and-recommendations">Considerations and Recommendations</h2>
<p>When integrating AI, there are numerous ethical considerations to acknowledge. Algorithmic bias can lead to unequal treatment of customers based off of aspects including gender, race, and or socioeconomic status. It is important to prioritize transparency and fairness. Businesses can avoid this by training the LLMs on diverse data sets and consistently monitoring and employing fairness checks during AI development and integration. Business should consider implementing strong security and safeguards to ensure user privacy. Furthermore, consistently refining training data and observing to prevent errors and bias is vital for optimizing performance.</p>
<p>In regards to job displacement, the fear surrounding AI replacing jobs is a valid concern <a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>. Although, businesses should emphasize the importance of human and AI collaboration. Focusing on AI augmenting human capabilities will allow service representatives to focus on complex interactions needing human connection, empathy, and nuanced understanding. Moreover, the development of explainable AI can make decision processes and algorithms more transparent and understandable for humans, which has the possibility to foster trust and confidence in their capabilities.</p>
<p>Artificial Intelligence continuously evolves, along with LLM technologies that provides advancements in customer service experiences. Enhanced Natural Language Processing (NLP) capabilities improves LLMs comprehension of complex inquiries and ability to generate nuanced responses. The advancements in NLPs empower LLMs to comprehend complex inquiries and respond with better accuracy. Capabilities such as sentiment analysis, allows LLMs to understand the emotional tone of customer messages. Moreover, topic modeling, helps categorize customer requests for efficient distribution<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>.</p>
<p>Productive customer service interactions depend on user compliance to a certain degree. Motivating customers to fill out surveys after LLM interactions can deliver useful feedback to implement improvements. Research recommends vigilant design approaches to possibly influence customers to comply with LLM requests. A study found that chatbots with anthropomorphic design cues (i.e., designed to seem more human-like) are more inclined to be perceived as having a the ability to socialize, which makes users more receptive to their requests. This spotlights the advantages of designing LLMs to accommodate users and cultivate a sense of connection with customers. Moreover, the foot-in-the-door technique, beginning with a minor request followed by a a larger one, has also been seen as effective in increasing user compliance in regards to chatbot requests<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>.</p>


</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Bock, Dora E., et al.&nbsp;“Artificial Intelligence: Disrupting What We Know about Services.” Journal of Services Marketing, Emerald Publishing Limited, 7 Apr.&nbsp;2020, www.emerald.com/insight/content/doi/10.1108/JSM-01-2019-0047/full/html.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Nisreen Ameen, et al.&nbsp;“Customer Experiences in the Age of Artificial Intelligence.” Computers in Human Behavior, Pergamon, 2 Sept.&nbsp;2020, www.sciencedirect.com/science/article/pii/S0747563220302983.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Pantano, Eleonora, and Gabriele Pizzi. “Forecasting Artificial Intelligence on Online Customer Assistance: Evidence from Chatbot Patents Analysis.” Journal of Retailing and Consumer Services, Pergamon, 18 Mar.&nbsp;2020, www.sciencedirect.com/science/article/pii/S0969698919311865.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Bock, Dora E., et al.&nbsp;“Artificial Intelligence: Disrupting What We Know about Services.” Journal of Services Marketing, Emerald Publishing Limited, 7 Apr.&nbsp;2020, www.emerald.com/insight/content/doi/10.1108/JSM-01-2019-0047/full/html.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Pantano, Eleonora, and Gabriele Pizzi. “Forecasting Artificial Intelligence on Online Customer Assistance: Evidence from Chatbot Patents Analysis.” Journal of Retailing and Consumer Services, Pergamon, 18 Mar.&nbsp;2020, www.sciencedirect.com/science/article/pii/S0969698919311865.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Nicolescu, Luminița, and Monica Teodora Tudorache. “Human-Computer Interaction in Customer Service: The Experience with AI Chatbots-A Systematic Literature Review.” MDPI, Multidisciplinary Digital Publishing Institute, 15 May 2022, www.mdpi.com/2079-9292/11/10/1579.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Can Ai Do Empathy Even Better than Humans? Companies Are Trying It. - WSJ, www.wsj.com/tech/ai/ai-empathy-business-applications-technology-fc41aea2. Accessed 16 May 2024.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Bock, Dora E., et al.&nbsp;“Artificial Intelligence: Disrupting What We Know about Services.” Journal of Services Marketing, Emerald Publishing Limited, 7 Apr.&nbsp;2020, www.emerald.com/insight/content/doi/10.1108/JSM-01-2019-0047/full/html.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Adam, Martin, et al.&nbsp;“(PDF) AI-Based Chatbots in Customer Service and Their Effects on User Compliance.” ResearchGate, www.researchgate.net/publication/339986693_AI-based_chatbots_in_customer_service_and_their_effects_on_user_compliance. Accessed 14 May 2024.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>Bock, Dora E., et al.&nbsp;“Artificial Intelligence: Disrupting What We Know about Services.” Journal of Services Marketing, Emerald Publishing Limited, 7 Apr.&nbsp;2020, www.emerald.com/insight/content/doi/10.1108/JSM-01-2019-0047/full/html.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>W.T. Ngai , Eric, et al.&nbsp;“An Intelligent Knowledge-Based Chatbot for Customer Service.” Electronic Commerce Research and Applications, Elsevier, 8 Oct.&nbsp;2021, www.sciencedirect.com/science/article/pii/S1567422321000703.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>Ruan, Yanya, and József Mezei. “When Do Ai Chatbots Lead to Higher Customer Satisfaction Than Human Frontline Employees in Online Shopping Assistance? Considering Product Attribute Type.” Journal of Retailing and Consumer Services, Pergamon, 25 June 2022, www.sciencedirect.com/science/article/pii/S0969698922001527#bib9.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>Ruan, Yanya, and József Mezei. “When Do Ai Chatbots Lead to Higher Customer Satisfaction Than Human Frontline Employees in Online Shopping Assistance? Considering Product Attribute Type.” Journal of Retailing and Consumer Services, Pergamon, 25 June 2022, www.sciencedirect.com/science/article/pii/S0969698922001527#bib9.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>Bock, Dora E., et al.&nbsp;“Artificial Intelligence: Disrupting What We Know about Services.” Journal of Services Marketing, Emerald Publishing Limited, 7 Apr.&nbsp;2020, www.emerald.com/insight/content/doi/10.1108/JSM-01-2019-0047/full/html.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>W.T. Ngai , Eric, et al.&nbsp;“An Intelligent Knowledge-Based Chatbot for Customer Service.” Electronic Commerce Research and Applications, Elsevier, 8 Oct.&nbsp;2021, www.sciencedirect.com/science/article/pii/S1567422321000703.<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>Adam, Martin, et al.&nbsp;“(PDF) AI-Based Chatbots in Customer Service and Their Effects on User Compliance.” ResearchGate, www.researchgate.net/publication/339986693_AI-based_chatbots_in_customer_service_and_their_effects_on_user_compliance. Accessed 14 May 2024.<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/dancerz\.github\.io\/comm4190_S24_Using_LLMs_Blog\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>